# gpu_test.py

import lightgbm as lgb
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ3ã‚¯ãƒ©ã‚¹ Ã— 2ã‚¯ãƒ©ã‚¹ã‚¿åˆ† â†’ n_informative>=3ã«ã™ã‚‹ï¼‰
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=5,
    n_redundant=0,
    n_classes=3,
    random_state=42
)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM Dataset
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test)

# GPUä½¿ç”¨ã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
params = {
    'device': 'gpu',
    'gpu_platform_id': 0,
    'gpu_device_id': 0,
    'boosting_type': 'gbdt',
    'objective': 'multiclass',
    'metric': 'multi_logloss',
    'num_class': 3,
    'verbosity': -1
}

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
print("ğŸš€ Training with GPU...")
model = lgb.train(
    params,
    train_data,
    valid_sets=[test_data],
    num_boost_round=100,
    callbacks=[
        lgb.early_stopping(stopping_rounds=10),
        lgb.log_evaluation(period=10)
    ]
)

# æ¨è«–ã¨è©•ä¾¡
y_pred = model.predict(X_test)
y_pred_labels = y_pred.argmax(axis=1)
acc = accuracy_score(y_test, y_pred_labels)

print(f"âœ… GPU Test Successful! Accuracy: {acc:.4f}")
